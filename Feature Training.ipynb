{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "from subprocess import Popen, PIPE\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lyrics = pd.read_csv('lyrics_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VOWELS = r'i|ɪ|e|ɛ|æ|a|ə|ɑ|ɒ|ɔ|ʌ|o|ʊ|u|y|ʏ|ø|œ|ɐ|ɜ|ɞ|ɘ|ɵ|ʉ|ɨ|ɤ|ɯ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_phonemes(line):\n",
    "    line = re.sub(r'\"', '', line)\n",
    "    \n",
    "    command = 'espeak --ipa -q \"{}\"'.format(line)\n",
    "    process = Popen(command, shell=True, stdout=PIPE)\n",
    "    \n",
    "    output, _ = process.communicate()\n",
    "    output = str(output, encoding='utf-8')\n",
    "    \n",
    "    phon_words = [re.sub('[^{}]'.format(VOWELS), '', word) for word in output.split()]\n",
    "    phon_concat = ''.join(re.findall(VOWELS, output))[::-1]\n",
    "    \n",
    "    return phon_words, phon_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_slice(index, lyrics, k):\n",
    "    lower = index - k / 2\n",
    "    upper = index + k / 2 - 1\n",
    "    \n",
    "    if lower < 0:\n",
    "        upper += -1 * lower\n",
    "        lower = 0\n",
    "    elif upper > lyrics.shape[0] - 1:\n",
    "        lower -= upper - lyrics.shape[0] - 1\n",
    "        upper = lyrics.shape[0] - 1\n",
    "          \n",
    "    return lyrics.loc[lower:upper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_candidates(input_phon, lyrics, k):\n",
    "    max_prefix = (0, 0)\n",
    "    \n",
    "    for i, phon in enumerate(lyrics.Vowels):\n",
    "        prefix_len = len(os.path.commonprefix([input_phon, phon]))\n",
    "        if prefix_len > max_prefix[1]:\n",
    "            max_prefix = (i, prefix_len)\n",
    "    \n",
    "    return get_slice(max_prefix[0], lyrics, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_features(input_line, line):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "    line = line.translate(translator)\n",
    "    input_line = input_line.translate(translator)\n",
    "    \n",
    "    # Semantic features\n",
    "    #subjects, objects, verbs, total = get_semantic_features(input_line, line)\n",
    "    jaccard, total = get_semantic_features(input_line, line)\n",
    "    \n",
    "    # Rhyming features\n",
    "    end_rhyme, total_rhyme = get_rhyme_features(input_line, line)\n",
    "    \n",
    "    # Other features\n",
    "    length = 1 - abs(len(input_line) - len(line)) / max(len(input_line), len(line))\n",
    "    \n",
    "    #return np.array([subjects, objects, verbs, total, end_rhyme, total_rhyme, length])\n",
    "    return np.array([jaccard, total, end_rhyme, total_rhyme, length])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.symbols import ORTH, LEMMA, POS\n",
    "from spacy.symbols import nsubj, VERB, dobj, NOUN\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp.tokenizer.add_special_case(u'gimme',\n",
    "    [\n",
    "        {\n",
    "            ORTH: u'gim',\n",
    "            LEMMA: u'give',\n",
    "            POS: u'VERB'},\n",
    "        {\n",
    "            ORTH: u'me'}])\n",
    "\n",
    "nlp.tokenizer.add_special_case(u'wanna',\n",
    "    [\n",
    "        {\n",
    "            ORTH: u'wan',\n",
    "            LEMMA: u'want',\n",
    "            POS: u'VERB'},\n",
    "        {\n",
    "            ORTH: u'na'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp.tokenizer.add_special_case(u'niggas',\n",
    "    [\n",
    "        {\n",
    "            ORTH: u'niggas',\n",
    "            LEMMA: u'nigga',\n",
    "            POS: u'NOUN'}])\n",
    "\n",
    "nlp.tokenizer.add_special_case(u'Niggas',\n",
    "    [\n",
    "        {\n",
    "            ORTH: u'niggas',\n",
    "            LEMMA: u'nigga',\n",
    "            POS: u'NOUN'}])\n",
    "\n",
    "nlp.tokenizer.add_special_case(u'Nigga',\n",
    "    [\n",
    "        {\n",
    "            ORTH: u'nigga',\n",
    "            LEMMA: u'nigga',\n",
    "            POS: u'NOUN'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_vector(word_set):\n",
    "    vectors = np.array([word.vector for word in word_set])\n",
    "    return np.nanmean(vectors, axis=0)\n",
    "\n",
    "def subjects_vector(doc):\n",
    "    subjects = set([token for token in doc if token.dep == nsubj])    \n",
    "    return average_vector(subjects)\n",
    "            \n",
    "def objects_vector(doc):\n",
    "    objects = set([token for token in doc if token.dep == dobj])                     \n",
    "    return average_vector(objects)\n",
    "\n",
    "def verbs_vector(doc):\n",
    "    verbs = set([token for token in doc if token.pos == VERB])\n",
    "    return average_vector(verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_semantic_features(input_line, line):\n",
    "    input_doc = nlp(str(input_line))\n",
    "    doc = nlp(str(line))\n",
    "    \n",
    "    input_subjects = subjects_vector(input_doc)\n",
    "    subjects = subjects_vector(doc)\n",
    "    sub_cos = compute_similarity(input_subjects, subjects)\n",
    "    \n",
    "    input_objects = objects_vector(input_doc)\n",
    "    objects = objects_vector(doc)\n",
    "    obj_cos = compute_similarity(input_objects, objects)\n",
    "    \n",
    "    input_verbs = verbs_vector(input_doc)\n",
    "    verbs = verbs_vector(doc)\n",
    "    verb_cos = compute_similarity(input_verbs, verbs)\n",
    "    \n",
    "    input_total = input_doc.vector\n",
    "    total = doc.vector\n",
    "    tot_cos = compute_similarity(input_total, total)\n",
    "    \n",
    "    return sub_cos, obj_cos, verb_cos, tot_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_semantic_features(input_line, line):\n",
    "    input_doc = nlp(str(input_line))\n",
    "    doc = nlp(str(line))\n",
    "    \n",
    "    input_total = input_doc.vector\n",
    "    total = doc.vector\n",
    "    tot_cos = compute_similarity(input_total, total)\n",
    "    \n",
    "    jaccard = compute_jaccard(input_doc, doc)\n",
    "    \n",
    "    return jaccard, tot_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_jaccard(input_doc, doc):\n",
    "    input_lemmas = {word.lemma_ for word in input_doc}\n",
    "    ref_lemmas = {word.lemma_ for word in doc}\n",
    "    \n",
    "    intersect = len(input_lemmas.intersection(ref_lemmas))\n",
    "    union = len(input_lemmas.union(ref_lemmas))\n",
    "    \n",
    "    return intersect / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_similarity(input_vector, ref_vector):\n",
    "    if not type(input_vector) is np.ndarray and not type(ref_vector) is np.ndarray:\n",
    "        return 1\n",
    "    elif not type(input_vector) is np.ndarray or not type(ref_vector) is np.ndarray:\n",
    "        return 0\n",
    "    else:\n",
    "        return cosine_similarity(input_vector.reshape(1, -1), ref_vector.reshape(1, -1))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_rhyme_features(input_line, line):\n",
    "    phon_words, phon_concat = get_phonemes(line)\n",
    "    input_phon_words, input_phon_concat = get_phonemes(input_line)\n",
    "    \n",
    "    end_rhyme = len(os.path.commonprefix([input_phon_concat, phon_concat]))\n",
    "       \n",
    "    total_rhyme = 0\n",
    "    for input_word in input_phon_words:\n",
    "        max_len = 0\n",
    "        for word in phon_words:\n",
    "            current_len = len(os.path.commonprefix([input_word, word]))\n",
    "            if current_len > max_len:\n",
    "                max_len = current_len\n",
    "        total_rhyme += max_len\n",
    "    total_rhyme /= len(input_phon_words)\n",
    "    \n",
    "    return end_rhyme, total_rhyme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_line(input_line, lyrics, coef, k=100, random_candidates=False):\n",
    "    _, input_phonemes = get_phonemes(input_line)\n",
    "    \n",
    "    if not random_candidates:\n",
    "        candidates = select_candidates(input_phonemes, lyrics, k)\n",
    "    else:\n",
    "        candidates = lyrics.sample(n=k)\n",
    "    \n",
    "    best = (0, '')\n",
    "    for _, candidate in candidates.iterrows():\n",
    "        features = calculate_features(input_line, candidate.Line)\n",
    "        score = np.dot(coef, features)\n",
    "        if score > best[0] and features[0] < 0.5:\n",
    "            best = (score, candidate.Line)\n",
    "    \n",
    "    return best[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_line(input_line, coef=[0.68, 0.12, -0.67, 0.08, 0.18], k=100, random_candidates=False):\n",
    "    # Mean and standard deviation of the the trianing data\n",
    "    mean = [0.05618665, 0.72029447, 1.11975, 0.71374178, 0.7401983]\n",
    "    std = [0.10824952, 0.15384646, 1.13375921, 0.27429371, 0.1920263]\n",
    "    \n",
    "    _, input_phonemes = get_phonemes(input_line)\n",
    "    \n",
    "    if not random_candidates:\n",
    "        candidates = select_candidates(input_phonemes, lyrics, k)\n",
    "    else:\n",
    "        candidates = lyrics.sample(n=k)\n",
    "        \n",
    "    semantic = coef[0] != 0 or coef[1] != 0\n",
    "    rhyme = coef[2] != 0 or coef[3] != 0\n",
    "    length = coef[4] != 0\n",
    "    \n",
    "    best = (-1, None)\n",
    "    for _, candidate in candidates.iterrows():\n",
    "        features = calculate_features(input_line, candidate.Line)\n",
    "        features = (features - mean) / std\n",
    "        score = np.dot(coef, features)\n",
    "        if score > best[0] and candidate.Line != input_line:\n",
    "            best = (score, candidate.Line)\n",
    "    \n",
    "    return best[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = lyrics.Line.loc[:5000]\n",
    "y = lyrics.NextLine.loc[:5000]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "truth_feat, other_feat = [], []\n",
    "\n",
    "for line, next_line in zip(X_train, y_train):\n",
    "    other_line = next_line\n",
    "    while other_line == next_line or other_line == line:\n",
    "        other_line = X.sample(n=1).iloc[0]\n",
    "    \n",
    "    truth = calculate_features(line, next_line)\n",
    "    other = calculate_features(line, other_line)\n",
    "    \n",
    "    truth_feat.append(truth)\n",
    "    other_feat.append(other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean = np.array(truth_feat + other_feat).mean(axis=0)\n",
    "std = np.array(truth_feat + other_feat).std(axis=0)\n",
    "\n",
    "truth_feat = (truth_feat - mean) / std\n",
    "other_feat = (other_feat - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_pairs,  y_pairs = [], []\n",
    "\n",
    "for truth, other in zip(truth_feat, other_feat):\n",
    "    if not random.getrandbits(1):\n",
    "        X_pairs.append(truth - other)\n",
    "        y_pairs.append(1)\n",
    "    else:\n",
    "        X_pairs.append(other - truth)\n",
    "        y_pairs.append(-1)\n",
    "        \n",
    "X_pairs, y_pairs = map(np.asanyarray, (X_pairs, y_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', C=.1)\n",
    "clf.fit(X_pairs, y_pairs)\n",
    "coef = clf.coef_.ravel() / np.linalg.norm(clf.coef_)\n",
    "\n",
    "with open('coefficients.txt', 'w') as f:\n",
    "    for value in coef:\n",
    "        f.write(str(value) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recall_1, recall_10, recall_50, recall_100 = 0, 0, 0, 0\n",
    "\n",
    "i = 1\n",
    "for line, next_line in zip(X_test[:50], y_test[:50]):\n",
    "    print('{0}: Processing: {1}'.format(i, line))\n",
    "    _, input_phonemes = get_phonemes(line)\n",
    "    candidates = select_candidates(input_phonemes, lyrics, 110)\n",
    "    \n",
    "    scores = []\n",
    "    for _, candidate in candidates.iterrows():\n",
    "        score = np.dot(coef, calculate_features(line, candidate.Line))\n",
    "        if candidate.Line.lower() != line:\n",
    "            scores.append((score, candidate.Line))\n",
    "        \n",
    "    ranking = sorted(scores, key=lambda x: x[0])\n",
    "    \n",
    "    for i, score in ranking:\n",
    "        if i == 0 and score[1] == next_line:\n",
    "            recall_1 += 1\n",
    "        elif i == 9 and score[1] == next_line:\n",
    "            recall_10 += 1\n",
    "        elif i == 49 and score[1] == next_line:\n",
    "            recall_50 += 1\n",
    "        elif i == 99 and score[1] == next_line:\n",
    "            recall_100 += 1\n",
    "            \n",
    "    i +=1\n",
    "    \n",
    "print(recall_1 / i, recall_10 / i, recall_50 / i, recall_100 / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I heard the bitch got hit with three zebras and a monkey'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_line(\"If I told you that a flower bloomed in a dark room, would you trust it?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
